############ Time Series Forecasting ######################
# Set Working Direction
setwd("C:/Users/ddfer/Desktop/MSBA Misc 2/Machine Learning 2/TP02")
#
rm(list=ls())
library(forecast)
library(glue)
library(e1071)
#
library(readr)
library(plyr) 
library(dbscan)
library(tidyverse)
library(lubridate)
library(dplyr)
library(data.table)
library(xgboost)
library(caret)
library(Matrix)
#

train <- read.csv("train.csv")
test <- read.csv("test.csv")
train$item <- as.factor(train$item)
train$store <- as.factor(train$store)
train$date <- as.Date(train$date, "%m/%d/%Y")

test$item <- as.factor(test$item)
test$store <- as.factor(test$store)
test$date <- as.Date(test$date, "%m/%d/%Y")

attach(train)

#vId=as.data.frame(test[,"id"])
#test$id=NULL
#test$sales=0

all_data <- train %>% bind_rows(test)

#Seasonality for stores 1-10
ggplot(all_data %>% filter(item == 2), aes(x= as.Date(date), y = sales)) + geom_line() + facet_wrap(~store)


summary(train)
dim(train)    #913000      4

#Adjust Stores and items here
#Store 5 item 1
train_sample_onestore <- data.frame(train[store == 5 & item == 1,]) #Train Sample
sample1store <- ts(train_sample_onestore$sales, frequency = 365, start=c(2013,1))
plot(sample1store, ylab = "Sales", xlab = "Years", main = "Store 5 Item 1")
summary(sample1store)

train_sample_allstores <- data.frame(train[store == 1:10 & item == 1,]) #Train Sample
sampleallstores <- ts(train_sample_allstores$sales, frequency = 365, start=c(2013,1))
plot(sampleallstores, ylab = "Sales", xlab = "Years", main = "All Stores Item 1")
summary(sampleallstores)

train_sample <- data.frame(train[store == 1:10 & item == 1,]) #Train Sample
sample_ts <- ts(train_sample$sales, frequency = 365, start=c(2013,1))

test_sample <- data.frame(test[store == 1:10 & item == 1,]) #Test Sample
test_ts <- ts(test_sample$sales, frequency = 365, start=c(2013,1))
#plot(test_ts) #Sales per item for example
plot(train_sample_onestore)

ndiffs(sample_ts)

###############################################################################
#Plots
#Naive Method
naiveTS <- naive(sample_ts, h = 90)
autoplot(naiveTS, ylab = "Sales", xlab = "Years", main = "Naive TS")
summary(naiveTS)

#Interpretation:
# Error measures:
#                       ME     RMSE  MAE     MPE     MAPE      MASE       ACF1
# Training set 0.007123288 6.482305 5.08 -8.7737 34.12977 0.9748956 -0.4733021

#RMSE is high, therefore, it is not great at forecasting, MAE is high as well
#Naive Method - Estimating technique in which the last period's actuals are used as this period's forecast, 
#without adjusting them or attempting to establish causal factors. 
#It is used only for comparison with the forecasts generated by the better (sophisticated) techniques.

#SNaive Method 
snaiveTS <- snaive(sample_ts, h = 90)
autoplot(snaiveTS, ylab = "Sales", xlab = "Years", main = "SNaive TS")
summary(snaiveTS)

#Interpretation:
# Error measures:
#                    ME     RMSE      MAE        MPE     MAPE MASE        ACF1
# Training set 1.249144 6.716769 5.210815 -0.9289991 32.52945    1 -0.02773318

#RMSE and MAE are still high


#SES Method 
sesTS <- ses(sample_ts, h = 90)
autoplot(sesTS, ylab = "Sales", xlab = "Years", main = "SES TS")
summary(sesTS)

#Interpretation:
# Error measures:
#                      ME     RMSE      MAE       MPE     MAPE      MASE        ACF1
# Training set 0.01945157 6.556213 5.110421 -8.945879 27.12256 0.6100193 -0.07533508

#RMSE and MAE still quite high 


###############################################################################
#Holt winters forecasting & residuals
holty <- holt(sample_ts, h =90)
autoplot(holty, ylab = "Sales", xlab = "Years", main = "Holt TS")
checkresiduals(holty)
summary(holty)

#Interpretation
# Error measures:
#                        ME     RMSE     MAE       MPE     MAPE      MASE        ACF1
# Training set -0.006091873 6.557286 5.11242 -9.070797 27.15833 0.6102579 -0.07548854

#Holt winters is one of the most popular ways to do a time series forecast.
#Way to model 3 aspects of time series, average, trend/slope, and seasonality

# for first graph, residuals are not correlated and have a 
#mean of zero therefore the residuals are useful and the holt method is a good forecasting model
# Same exists as above for the bottom right graph
# However, for bottom left plot there with a huge amount of the data failing the
#box test, there looks to be some autocorrelation in the data


#Forecasting with ARIMA
Smodel1<-Arima(sample_ts,order=c(0,1,0), 
               seasonal=list(order=c(1,1,0),period=4)) 
Smodel1 #AIC=12766.63   AICc=12766.64   BIC=12777.64

Smodel2<-Arima(sample_ts,order=c(0,1,2), 
               seasonal=list(order=c(1,1,0),period=4)) 
Smodel2 #AIC=11538.43   AICc=11538.45   BIC=11560.46

model_sarima <- auto.arima(sample_ts)
model_sarima


acfmod <- Acf(model_sarima$residuals, lag.max = 100, ci=0.99, main="White Noise")     #Looks like white noise
autoplot(acfmod)

pacfmod <- Pacf(model_sarima$residuals, lag.max = 100, ci=0.99, main = "White Noise")  #Looks like white noise
autoplot(pacfmod)


Box.test(model_sarima$residuals)








